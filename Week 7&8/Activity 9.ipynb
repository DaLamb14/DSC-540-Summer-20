{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7 Activity 1: Top 100 ebooks' name extraction from Gutenberg.org\n",
    "\n",
    "## What is Project Gutenberg? - \n",
    "Project Gutenberg is a volunteer effort to digitize and archive cultural works, to \"encourage the creation and distribution of eBooks\". It was founded in 1971 by American writer Michael S. Hart and is the **oldest digital library.** This longest-established ebook project releases books that entered the public domain, and can be freely read or downloaded in various electronic formats.\n",
    "\n",
    "## What is this activity all about?\n",
    "* **This activity aims to scrape the url of the Project Gutenberg's Top 100 ebooks (yesterday's ranking) for identifying the ebook links. **\n",
    "* **It uses BeautifulSoup4 for parsing the HTML and regular expression code for identifying the Top 100 ebook file numbers.**\n",
    "* **You can use those book ID numbers to download the book into your local drive if you want**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries including regex, and beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore SSL errors (this code will be given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the HTML from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/browse/scores/top\"\n",
    "response= requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a small function to check the status of web request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status(response):\n",
    "    if response.status_code == 200:\n",
    "        print(\"Loaded\")\n",
    "    else:\n",
    "        print(\"There was a problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "status(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode the response and pass on to `BeautifulSoup` for HTML parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = response.content.decode(response.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(decode, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all the _href_ tags and store them in the list of links. Check how the list looks like - print first 30 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for tag in soup.find_all(\"a\"):\n",
    "    tags.append(tag.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Main_Page',\n",
       " '/catalog/',\n",
       " '/ebooks/',\n",
       " '/browse/recent/last1',\n",
       " '/browse/scores/top',\n",
       " '/wiki/Gutenberg:Offline_Catalogs',\n",
       " '/catalog/world/mybookmarks',\n",
       " '/wiki/Main_Page',\n",
       " 'https://www.paypal.com/xclick/business=donate%40gutenberg.org&item_name=Donation+to+Project+Gutenberg',\n",
       " '/wiki/Gutenberg:Project_Gutenberg_Needs_Your_Donation',\n",
       " 'http://www.ibiblio.org',\n",
       " 'http://www.pgdp.net/',\n",
       " 'pretty-pictures',\n",
       " '#books-last1',\n",
       " '#authors-last1',\n",
       " '#books-last7',\n",
       " '#authors-last7',\n",
       " '#books-last30',\n",
       " '#authors-last30',\n",
       " '/ebooks/1342',\n",
       " '/ebooks/11',\n",
       " '/ebooks/2701',\n",
       " '/ebooks/1661',\n",
       " '/ebooks/1635',\n",
       " '/ebooks/25525',\n",
       " '/ebooks/1952',\n",
       " '/ebooks/1080',\n",
       " '/ebooks/2542',\n",
       " '/ebooks/74',\n",
       " '/ebooks/98']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use regular expression to find the numeric digits in these links. <br>These are the file number for the Top 100 books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize empty list to hold the file numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number 19 to 118 in the original list of links have the Top 100 ebooks' number. \n",
    "* Loop over appropriate range and use regex to find the numeric digits in the link (href) string.\n",
    "* Hint: Use `findall()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(19,119):\n",
    "    tag = tags[i]\n",
    "    tag = tag.strip()\n",
    "    file = re.findall(\"[0-9]+\", tag)\n",
    "    #looking for numbers so 0-9\n",
    "    if len(file) == 1:\n",
    "        files.append(int(file[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the file numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1342,\n",
       " 11,\n",
       " 2701,\n",
       " 1661,\n",
       " 1635,\n",
       " 25525,\n",
       " 1952,\n",
       " 1080,\n",
       " 2542,\n",
       " 74,\n",
       " 98,\n",
       " 46,\n",
       " 84,\n",
       " 205,\n",
       " 2600,\n",
       " 2591,\n",
       " 5200,\n",
       " 76,\n",
       " 43,\n",
       " 844,\n",
       " 514,\n",
       " 1184,\n",
       " 14975,\n",
       " 120,\n",
       " 4300,\n",
       " 345,\n",
       " 174,\n",
       " 1727,\n",
       " 1232,\n",
       " 58975,\n",
       " 158,\n",
       " 6130,\n",
       " 62678,\n",
       " 408,\n",
       " 42108,\n",
       " 203,\n",
       " 1400,\n",
       " 1260,\n",
       " 1497,\n",
       " 16328,\n",
       " 16,\n",
       " 2554,\n",
       " 376,\n",
       " 28054,\n",
       " 45,\n",
       " 58585,\n",
       " 5740,\n",
       " 996,\n",
       " 4363,\n",
       " 27827,\n",
       " 1998,\n",
       " 19033,\n",
       " 219,\n",
       " 244,\n",
       " 135,\n",
       " 730,\n",
       " 3600,\n",
       " 2852,\n",
       " 55,\n",
       " 62677,\n",
       " 36,\n",
       " 62682,\n",
       " 33283,\n",
       " 2680,\n",
       " 4507,\n",
       " 20738,\n",
       " 62668,\n",
       " 113,\n",
       " 2814,\n",
       " 160,\n",
       " 863,\n",
       " 768,\n",
       " 766,\n",
       " 215,\n",
       " 2097,\n",
       " 62680,\n",
       " 147,\n",
       " 8800,\n",
       " 1250,\n",
       " 25344,\n",
       " 62669,\n",
       " 1399,\n",
       " 3207,\n",
       " 23,\n",
       " 2500,\n",
       " 3296,\n",
       " 3090,\n",
       " 521,\n",
       " 43453,\n",
       " 20203,\n",
       " 148,\n",
       " 3825,\n",
       " 30254,\n",
       " 829,\n",
       " 100,\n",
       " 236,\n",
       " 25717,\n",
       " 1228,\n",
       " 161,\n",
       " 61]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the `soup` object's text look like? Use `.text()` method and print only first 2000 characters (i.e. do not print the whole thing, it is long).\n",
    "\n",
    "You will notice lot of empty spaces/blanks here and there. Ignore them. They are part of HTML page markup and its whimsical nature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\n\\n\\n      if (top != self) {\\n        top.location.replace ('http://www.gutenberg.org');\\n        alert ('Project Gutenberg is a FREE service with NO membership required. If you paid somebody else to get here, make them give you your money back!');\\n      }\\n    \\n \\nTop 100 - Project Gutenberg\\n\\n\\n\\n\\n\\n\\n\\n\\nOnline Book Catalog\\n=> \\n\\n\\n\\n Book  Search\\n-- Recent  Books\\n-- Top  100\\n-- Offline Catalogs\\n-- My Bookmarks\\n\\n\\nMain Page\\n\\n\\n\\n\\nProject Gutenberg needs your donation! \\n        More Info\\n\\n\\n\\n\\n\\n\\n\\n\\nDid you know that you can help us produce ebooks\\nby proof-reading just one page a day?\\nGo to: Distributed Proofreaders\\n\\n\\n\\nTop 100\\n\\n\\nTo determine the ranking we count the times each file gets downloaded.\\nBoth HTTP and FTP transfers are counted.\\nOnly transfers from ibiblio.org are counted as we have no access to our mirrors log files.\\nMultiple downloads from the same IP address on the same day count as one download.\\nIP addresses that download more than 100 files a day are considered\\nrobots and are not considered.\\nBooks made out of multiple files like most audio books are counted\\nif any file is downloaded.\\n\\nDownloaded Books\\n2020-07-17175423\\nlast 7 days1183983\\nlast 30 days5410249\\n\\nPretty Pictures\\n\\nTop 100 EBooks yesterday —\\n  Top 100 Authors yesterday —\\n  Top 100 EBooks last 7 days —\\n  Top 100 Authors last 7 days —\\n  Top 100 EBooks last 30 days —\\n  Top 100 Authors last 30 days\\n\\nTop 100 EBooks yesterday\\n\\nPride and Prejudice by Jane Austen (1469)\\nAlice's Adventures in Wonderland by Lewis Carroll (1095)\\nMoby Dick; Or, The Whale by Herman Melville (770)\\nThe Adventures of Sherlock Holmes by Arthur Conan Doyle (748)\\nIon by Plato (716)\\nThe Works of Edgar Allan Poe, The Raven Edition by Edgar Allan Poe (649)\\nThe Yellow Wallpaper by Charlotte Perkins Gilman (646)\\nA Modest Proposal by Jonathan Swift (588)\\nEt dukkehjem. English by Henrik Ibsen (547)\\nThe Adventures of Tom Sawyer by Mark Twain (521)\\nA Tale of Two Cities by Charles Dickens (510)\\nA Christmas Carol in Prose; Being a Ghost Story of Christ\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in the extracted text (using regular expression) from the `soup` object to find the names of top 100 Ebooks (Yesterday's rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a starting index. It should point at the text _\"Top 100 Ebooks yesterday\"_. Hint: Use `splitlines()` method of the `soup.text`. It splits the lines of the text of the `soup` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = soup.text.splitlines().index(\"Top 100 EBooks yesterday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop 1-100 to add the strings of next 100 lines to this temporary list. Hint: `splitlines()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    enames.append(soup.text.splitlines()[index+2+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use regular expression to extract only text from the name strings and append to an empty list\n",
    "* Hint: Use `match` and `span` to find indices and use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enames2 = []\n",
    "for i in range(100):\n",
    "    id1, id2 = re.match(\"^[a-zA-Z]*\", enames[i]).span()\n",
    "    enames2.append(enames[i][id1:id2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride\n",
      "Alice\n",
      "Moby\n",
      "The\n",
      "Ion\n",
      "The\n",
      "The\n",
      "A\n",
      "Et\n",
      "The\n",
      "A\n",
      "A\n",
      "Frankenstein\n",
      "Walden\n",
      "War\n",
      "Grimms\n",
      "Metamorphosis\n",
      "Adventures\n",
      "The\n",
      "The\n",
      "Little\n",
      "The\n",
      "Southern\n",
      "Treasure\n",
      "Ulysses\n",
      "Dracula\n",
      "The\n",
      "The\n",
      "Il\n",
      "Index\n",
      "Emma\n",
      "The\n",
      "Some\n",
      "The\n",
      "The\n",
      "Uncle\n",
      "Great\n",
      "Jane\n",
      "The\n",
      "Beowulf\n",
      "Peter\n",
      "Prestuplenie\n",
      "A\n",
      "The\n",
      "Anne\n",
      "The\n",
      "Tractatus\n",
      "Don\n",
      "Beyond\n",
      "The\n",
      "Also\n",
      "Alice\n",
      "Heart\n",
      "A\n",
      "Les\n",
      "Oliver\n",
      "Essays\n",
      "The\n",
      "The\n",
      "Street\n",
      "The\n",
      "The\n",
      "Calculus\n",
      "Meditations\n",
      "As\n",
      "Diccionario\n",
      "La\n",
      "The\n",
      "Dubliners\n",
      "The\n",
      "The\n",
      "Wuthering\n",
      "David\n",
      "The\n",
      "The\n",
      "The\n",
      "Common\n",
      "An\n",
      "Anthem\n",
      "The\n",
      "The\n",
      "Anna\n",
      "Leviathan\n",
      "Narrative\n",
      "Siddhartha\n",
      "The\n",
      "Complete\n",
      "The\n",
      "A\n",
      "Autobiography\n",
      "The\n",
      "Pygmalion\n",
      "The\n",
      "Gulliver\n",
      "The\n",
      "The\n",
      "The\n",
      "On\n",
      "Sense\n",
      "Manifest\n"
     ]
    }
   ],
   "source": [
    "for i in enames2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
